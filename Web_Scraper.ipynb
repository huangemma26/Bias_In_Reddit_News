{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# web scraping libraries\n",
    "from __future__ import print_function, division\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# time libraries\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from time import sleep\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a new user agent\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes from reddit's HTML\n",
    "upvote_class = \"score unvoted\"\n",
    "title_class = \"title may-blank outbound\"\n",
    "url_class = \"domain\"\n",
    "time_class = \"live-timestamp\"\n",
    "comment_class = \"first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_value(soup, class_name):\n",
    "    \n",
    "    obj = soup.find_all(class_ = class_name)\n",
    "    \n",
    "    if not obj: \n",
    "        return None\n",
    "    else: return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upvote_list(html_list):\n",
    "    upvote_list = []\n",
    "    for item in html_list:\n",
    "        upvotes = item.text\n",
    "        if upvotes.isdigit() == True:\n",
    "            upvote_list.append(int(upvotes))\n",
    "        else:\n",
    "            if upvotes == 'â€¢':\n",
    "                upvote_list.append(0)\n",
    "            else:\n",
    "                upvote_list.append(int(float(upvotes[:-1])*1000))\n",
    "    return upvote_list\n",
    "\n",
    "def get_title_list(html_list):\n",
    "    title_list = []\n",
    "    for item in html_list:\n",
    "        title_list.append(item.text)\n",
    "    return title_list\n",
    "\n",
    "def get_url_list(html_list):\n",
    "    url_list = []\n",
    "    for item in html_list:\n",
    "        final_item = item.text.split('(')[1]\n",
    "        final_item = final_item.split(')')[0]\n",
    "        url_list.append(final_item)\n",
    "    return url_list\n",
    "\n",
    "def get_time_list(html_list):\n",
    "    time_list = []\n",
    "    for item in html_list:\n",
    "        final_item = item[\"datetime\"]\n",
    "        final_item = final_item[:-6] + \"Z\"\n",
    "        final_item = datetime.datetime.strptime(final_item, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        time_list.append(final_item)\n",
    "    return time_list\n",
    "\n",
    "def get_length_list(complied_times):\n",
    "    length_list = []\n",
    "    for item in times:\n",
    "        length_list.append(datetime.datetime.utcnow()-item)\n",
    "    return length_list\n",
    "\n",
    "def get_comment_list(html_list):\n",
    "    comment_list = []\n",
    "    for item in html_list:\n",
    "        blah = item.text.split(\" \")[0]\n",
    "        if blah.isdigit() == True:\n",
    "            comment_list.append(int(blah))\n",
    "        else:\n",
    "            comment_list.append(0)\n",
    "    return comment_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape a list of urls to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "list_length = 0\n",
    "\n",
    "# initial url\n",
    "url_list = ['https://old.reddit.com/r/worldnews/new/']\n",
    "\n",
    "# reddit only saves 31 pages\n",
    "while list_length < 30:\n",
    "    start_url = url_list[list_length]\n",
    "    response = requests.get(start_url, headers=user_agent)\n",
    "    print(response.status_code)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    for item in soup.find(class_ = \"next-button\")('a'):\n",
    "        url = item['href']\n",
    "    url_list.append(url)\n",
    "    list_length += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate through the list of urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "headers2 = ['upvotes', 'title', 'site', 'time_posted', 'post_age', 'comment_no']\n",
    "\n",
    "post_data = []\n",
    "\n",
    "for url in url_list:\n",
    "    \n",
    "#     headers = {'User-agent': ua.random}\n",
    "    response = requests.get(url, headers=user_agent)\n",
    "    print(response.status_code)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    upvotes = get_post_value(soup, upvote_class)\n",
    "    upvotes = get_upvote_list(upvotes)\n",
    "    \n",
    "    titles = get_post_value(soup, title_class)\n",
    "    titles = get_title_list(titles)\n",
    "\n",
    "    urls = get_post_value(soup, url_class)\n",
    "    urls = get_url_list(urls)\n",
    "\n",
    "    times = get_post_value(soup, time_class)\n",
    "    times = get_time_list(times)\n",
    "\n",
    "    lengths = get_length_list(times)\n",
    "\n",
    "    comments = get_post_value(soup, comment_class)\n",
    "    comments = get_comment_list(comments)\n",
    "    \n",
    "    for upvote, title, url, time, length, comment in zip(upvotes,titles,urls,times,lengths,comments):\n",
    "        post_dict = dict(zip(headers2, [upvote,\n",
    "                                title,\n",
    "                                url,\n",
    "                                time,\n",
    "                                length,\n",
    "                                comment]))\n",
    "        post_data.append(post_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a dataframe\n",
    "post_df = pd.DataFrame(post_data)\n",
    "post_df = post_df[['upvotes', 'title', 'site', 'time_posted','post_age', 'comment_no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 771 entries, 0 to 770\n",
      "Data columns (total 6 columns):\n",
      "upvotes        771 non-null int64\n",
      "title          771 non-null object\n",
      "site           771 non-null object\n",
      "time_posted    771 non-null datetime64[ns]\n",
      "post_age       771 non-null timedelta64[ns]\n",
      "comment_no     771 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2), object(2), timedelta64[ns](1)\n",
      "memory usage: 36.2+ KB\n"
     ]
    }
   ],
   "source": [
    "post_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upvotes</th>\n",
       "      <th>title</th>\n",
       "      <th>site</th>\n",
       "      <th>time_posted</th>\n",
       "      <th>post_age</th>\n",
       "      <th>comment_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Boycott activists fined for canceled Lorde con...</td>\n",
       "      <td>dw.com</td>\n",
       "      <td>2018-10-14 18:40:00</td>\n",
       "      <td>00:05:55.062292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>No deal yet after flurry of Brexit diplomacy i...</td>\n",
       "      <td>reuters.com</td>\n",
       "      <td>2018-10-14 18:39:37</td>\n",
       "      <td>00:06:18.062296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Saudi Arabia threatens US \"you will stab your ...</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td>2018-10-14 18:38:27</td>\n",
       "      <td>00:07:28.062296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S. wants 'regime change' in Iran: Rouhani</td>\n",
       "      <td>reuters.com</td>\n",
       "      <td>2018-10-14 18:37:59</td>\n",
       "      <td>00:07:56.062297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Netherlands in a â€˜cyberwarâ€™ with Russia, says ...</td>\n",
       "      <td>guardian.ng</td>\n",
       "      <td>2018-10-14 18:35:32</td>\n",
       "      <td>00:10:23.062297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   upvotes                                              title         site  \\\n",
       "0        0  Boycott activists fined for canceled Lorde con...       dw.com   \n",
       "1        0  No deal yet after flurry of Brexit diplomacy i...  reuters.com   \n",
       "2        0  Saudi Arabia threatens US \"you will stab your ...      cnn.com   \n",
       "3        0        U.S. wants 'regime change' in Iran: Rouhani  reuters.com   \n",
       "4        0  Netherlands in a â€˜cyberwarâ€™ with Russia, says ...  guardian.ng   \n",
       "\n",
       "          time_posted        post_age  comment_no  \n",
       "0 2018-10-14 18:40:00 00:05:55.062292           1  \n",
       "1 2018-10-14 18:39:37 00:06:18.062296           1  \n",
       "2 2018-10-14 18:38:27 00:07:28.062296           0  \n",
       "3 2018-10-14 18:37:59 00:07:56.062297           0  \n",
       "4 2018-10-14 18:35:32 00:10:23.062297           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a csv file\n",
    "# post_df.to_csv(\"post_data_10_10.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
